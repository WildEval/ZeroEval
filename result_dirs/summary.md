| Model                         |   MMLU<br/>-Redux |   ZebraLogic<br/>-Easy |   CRUX |   MATH<br/>-L5 |   Average |
|:------------------------------|------------------:|-----------------------:|-------:|---------------:|----------:|
| gpt-4o-2024-08-06             |             88.26 |                  84.64 |  85.00 |          55.34 |     78.31 |
| gemini-1.5-pro-exp-0827       |             86.14 |                  79.64 |  77.62 |          68.10 |     77.88 |
| chatgpt-4o-latest-24-09-07    |             88.88 |                  81.43 |  84.25 |          53.12 |     76.92 |
| gpt-4o-2024-05-13             |             88.01 |                  77.86 |  83.62 |          54.79 |     76.07 |
| claude-3-5-sonnet-20240620    |             86.00 |                  87.50 |  78.75 |          51.87 |     76.03 |
| Llama-3.1-405B-Inst@sambanova |             86.21 |                  84.64 |  71.25 |          49.79 |     72.97 |
| gpt-4-turbo-2024-04-09        |             85.31 |                  80.71 |  76.75 |          46.46 |     72.31 |
| Mistral-Large-2               |             82.97 |                  80.36 |  72.88 |          48.54 |     71.19 |
| gpt-4o-mini-2024-07-18        |             81.50 |                  62.50 |  73.50 |          52.15 |     67.41 |
| claude-3-opus-20240229        |             82.54 |                  78.21 |  68.62 |          36.89 |     66.56 |
| Meta-Llama-3.1-70B-Instruct   |             82.97 |                  73.57 |  62.62 |          43.13 |     65.57 |
| deepseek-v2.5-0908            |             80.35 |                  68.21 |  68.12 |          44.66 |     65.34 |
| gpt-4-0314                    |             81.64 |                  77.14 |  72.38 |          26.07 |     64.31 |
| gemini-1.5-pro                |             82.76 |                  55.71 |  66.25 |          39.81 |     61.13 |
| Qwen2-72B-Instruct            |             81.61 |                  63.93 |  57.38 |          38.28 |     60.30 |
| gemini-1.5-flash              |             77.36 |                  59.29 |  61.88 |          34.81 |     58.34 |
| Meta-Llama-3-70B-Instruct     |             78.01 |                  52.86 |  57.12 |          25.10 |     53.27 |
| gemma-2-27b-it                |             75.67 |                  50.71 |  55.88 |          26.63 |     52.22 |
| Athene-70B                    |             76.64 |                  52.50 |  49.75 |          20.67 |     49.89 |
| claude-3-haiku-20240307       |             72.32 |                  47.86 |  53.62 |          15.12 |     47.23 |
| reka-core-20240501            |             76.42 |                  43.21 |  45.00 |          21.91 |     46.63 |
| gemma-2-9b-it                 |             72.82 |                  41.79 |  44.88 |          19.42 |     44.73 |
| Meta-Llama-3.1-8B-Instruct    |             67.24 |                  43.57 |  38.75 |          22.19 |     42.94 |
| Yi-1.5-34B-Chat               |             72.79 |                  37.50 |  42.88 |          18.17 |     42.84 |
| gpt-3.5-turbo-0125            |             68.36 |                  33.57 |  53.25 |          13.73 |     42.23 |
| Phi-3-mini-4k-instruct        |             70.34 |                  38.21 |  43.50 |          16.23 |     42.07 |
| Qwen2-7B-Instruct             |             66.92 |                  29.29 |  36.75 |          23.86 |     39.20 |
| Phi-3.5-mini-instruct         |             67.67 |                  21.79 |  40.88 |          18.72 |     37.27 |
| Meta-Llama-3-8B-Instruct      |             61.66 |                  40.71 |  36.62 |           7.91 |     36.73 |
| Yi-1.5-9B-Chat                |             65.05 |                   8.21 |  43.75 |          19.97 |     34.24 |
| gemma-2-2b-it                 |             51.94 |                  14.29 |  20.75 |           4.30 |     22.82 |