| Model                      |   MMLU<br/>-Redux |   ZebraLogic<br/>-Easy |   CRUX |   MATH<br/>-L5 |   Average |
|:---------------------------|------------------:|-----------------------:|-------:|---------------:|----------:|
| gpt-4o-2024-08-06          |             88.26 |                  84.64 |  85.00 |          55.34 |     78.31 |
| gpt-4o-2024-05-13          |             88.01 |                  77.86 |  83.62 |          54.79 |     76.07 |
| claude-3-5-sonnet-20240620 |             86.00 |                  87.50 |  78.75 |          51.87 |     76.03 |
| Mistral-Large-2            |             82.97 |                  80.36 |  72.88 |          48.54 |     71.19 |
| gpt-4o-mini-2024-07-18     |             81.50 |                  62.50 |  73.50 |          52.15 |     67.41 |
| gemini-1.5-pro             |             82.76 |                  55.71 |  66.25 |          39.81 |     61.13 |
| Qwen2-72B-Instruct         |             81.61 |                  63.93 |  57.38 |          38.28 |     60.30 |
| gemma-2-27b-it             |             75.67 |                  50.71 |  55.88 |          26.63 |     52.22 |
| claude-3-haiku-20240307    |             72.32 |                  47.86 |  53.62 |          15.12 |     47.23 |
| gemma-2-9b-it              |             72.82 |                  41.79 |  44.88 |          19.42 |     44.73 |
| Meta-Llama-3.1-8B-Instruct |             67.24 |                  43.57 |  38.75 |          22.19 |     42.94 |
| Yi-1.5-34B-Chat            |             72.79 |                  37.50 |  42.88 |          18.17 |     42.84 |
| gpt-3.5-turbo-0125         |             68.36 |                  33.57 |  53.25 |          13.73 |     42.23 |
| Phi-3-mini-4k-instruct     |             70.34 |                  38.21 |  43.50 |          16.23 |     42.07 |